{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse et visualisation de données avec Python\n",
    "## Collection de jeux de données Vega\n",
    "Cette page contient des exercices basés sur les données de la collection Vega.\n",
    "\n",
    "\n",
    "* Dépôt GitHub de [Vega Datasets](https://github.com/vega/vega-datasets).\n",
    "  * [Origine](https://github.com/vega/vega-datasets/blob/master/SOURCES.md) des différents fichiers.\n",
    "* Les exercices ci-dessous supposent que la copie locale partage le même dossier parent que `analyse-donnees-python`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "dossier_data = os.path.join(\"..\" if os.path.basename(os.getcwd()) == \"solutions\" else \".\",\n",
    "                            \"..\", \"..\", \"vega-datasets\", \"data\")\n",
    "print(dossier_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les différents fichiers CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher uniquement les fichiers *.csv\n",
    "glob.glob(os.path.join(dossier_data, \"*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de chargement des données\n",
    "pd.read_csv(os.path.join(dossier_data, \"airports.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les différents fichiers JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher uniquement les fichiers *.json\n",
    "glob.glob(os.path.join(dossier_data, \"*.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de chargement des données\n",
    "pd.read_json(os.path.join(dossier_data, \"cars.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1 - Grouper des données\n",
    "Dans le tableau ci-dessous, il y a en première colonne une sélection de fichiers de données. Pour chacun de ces fichiers, le tableau suggère trois variables à considérer pour le calcul d'une statistique descriptive. Veuillez vous référer à ce tableau pour les prochaines étapes de l'exercice.\n",
    "\n",
    " Fichier           | `variable1`   | `variable2`       | `variable3`   | Statistique\n",
    "------------------ | ------------- | ----------------- | ------------- | -----------\n",
    "`birdstrikes.csv`  | `Time of day` | `Phase of flight` | `Flight Date` | `count()`\n",
    "`cars.json`        | `Cylinders`   | `Origin`          | `Miles_per_Gallon` | `median()`\n",
    "`flights-20k.json` | `origin`      | `destination`     | `delay`       | `max()`\n",
    "`football.json`    | `division`    | `home_score`      | `away_score`  | `mean()`\n",
    "`jobs.json`        | `year`        | `sex`             | `perc`        | `sum()`\n",
    "`movies.json`      | `Creative Type` | `MPAA Rating`   | `US Gross`    | `mean()`\n",
    "`penguins.json`    | `Island`      | `Species`         | `Body Mass (g)` | `count()`\n",
    "`population.json`  | `year`        | `age`             | `people`      | `sum()`\n",
    "`weather.csv`      | `weather`     | `location`        | `wind`        | `max()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Choisissez un fichier de données et chargez les données dans un DataFrame Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fic_ind = -1\n",
    "fic_var = [\n",
    "    {'f': \"birdstrikes.csv\",  'v1': 'Time of day', 'v2': 'Phase of flight', 'v3': 'Flight Date'},\n",
    "    {'f': \"cars.json\",        'v1': 'Cylinders',   'v2': 'Origin',     'v3': 'Miles_per_Gallon'},\n",
    "    {'f': \"flights-20k.json\", 'v1': 'origin',      'v2': 'destination',     'v3': 'delay'},\n",
    "    {'f': \"football.json\",    'v1': 'division',    'v2': 'home_score',      'v3': 'away_score'},\n",
    "    {'f': \"jobs.json\",        'v1': 'year',        'v2': 'sex',             'v3': 'perc'},\n",
    "    {'f': \"movies.json\",      'v1': 'Creative Type', 'v2': 'MPAA Rating',   'v3': 'US Gross'},\n",
    "    {'f': \"penguins.json\",    'v1': 'Island',      'v2': 'Species',         'v3': 'Sex'},\n",
    "    {'f': \"population.json\",  'v1': 'year',        'v2': 'age',             'v3': 'people'},\n",
    "    {'f': \"weather.csv\",      'v1': 'weather',     'v2': 'location',        'v3': 'wind'}]\n",
    "\n",
    "nom_fichier = fic_var[fic_ind]['f']\n",
    "print(\"Nom du fichier retenu :\", nom_fichier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \".csv\" in nom_fichier:\n",
    "    df = pd.read_csv(os.path.join(dossier_data, nom_fichier))\n",
    "elif \".json\" in nom_fichier:\n",
    "    df = pd.read_json(os.path.join(dossier_data, nom_fichier))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Groupez les données selon `variable1` et `variable2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selon_v1v2 = df.groupby([fic_var[fic_ind]['v1'], fic_var[fic_ind]['v2']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Calculez la statistique descriptive de la variable `variable3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_v3 = selon_v1v2[fic_var[fic_ind]['v3']].max()\n",
    "stat_v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Créez un \"bar-plot\" montrant la statistique selon les deux variables choisies. Pour plus de visibilité avec certaines données, les barres seront empilées (*stacked*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_v3_tableau = stat_v3.unstack()\n",
    "stat_v3_tableau.plot(kind='bar', title=fic_var[fic_ind]['v3'], stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2 - Sélection des données\n",
    "Choisir un des fichiers ci-dessous, charger les données dans un DataFrame et résoudre le problème correspondant.\n",
    "\n",
    "* `birdstrikes.csv`\n",
    "* `cars.json`\n",
    "* `flights-3m.csv`\n",
    "* `football.json`\n",
    "* `jobs.json`\n",
    "* `movies.json`\n",
    "* `penguins.json`\n",
    "* `weather.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fic_ind = -1\n",
    "fic_list = [\n",
    "    \"birdstrikes.csv\",\n",
    "    \"cars.json\",\n",
    "    \"flights-3m.csv\",\n",
    "    \"football.json\",\n",
    "    \"jobs.json\",\n",
    "    \"movies.json\",\n",
    "    \"penguins.json\",\n",
    "    \"weather.csv\"]\n",
    "\n",
    "nom_fichier = fic_list[fic_ind]\n",
    "print(\"Nom du fichier retenu :\", nom_fichier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \".csv\" in nom_fichier:\n",
    "    df = pd.read_csv(os.path.join(dossier_data, nom_fichier))\n",
    "elif \".json\" in nom_fichier:\n",
    "    df = pd.read_json(os.path.join(dossier_data, nom_fichier))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour `birdstrikes.csv`\n",
    "Calculez la somme des `Cost Repair` pour chaque `Aircraft Airline Operator` lorsque le `Cost Other` est plus grand que 0$, et ce, pour les vols d'avant 2001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = df[(df['Flight Date'] < \"2001\") & (df['Cost Other'] > 0)]\n",
    "selection.groupby('Aircraft Airline Operator')['Cost Repair'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour `cars.json`\n",
    "Affichez le nom de modèle et l'accélération des automobiles de dernière année parmi tous les modèles japonais ou ceux ayant une efficacité d'au moins 30 `Miles_per_Gallon`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "econo = df[(df['Origin'] == 'Japan') | (df['Miles_per_Gallon'] >= 30)]\n",
    "econo[econo['Year'] == econo['Year'].max()][['Name', 'Acceleration']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour `flights-3m.csv`\n",
    "On veut calculer le délai moyen pour toutes les paires d'aéroports `(origin,destination)` qui sont parmi les aéroports `ABQ`, `LAX`, `PHX` et `SAN`:\n",
    "* Sélectionnez les enregistrements lorsque l'origine et la destination font partie des quatre aéroports mentionnés.\n",
    "* Calculez le délai moyen selon chaque paire d'aéroports.\n",
    "* Transformez le résultat en tableau pour que chaque destination soit une colonne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes_iata = ['ABQ', 'LAX', 'PHX', 'SAN']\n",
    "enregistrements = df[df['origin'].isin(codes_iata) & df['destination'].isin(codes_iata)]\n",
    "moyennes = enregistrements.groupby(['origin', 'destination'])['delay'].mean()\n",
    "moyennes.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour `football.json`\n",
    "Pour chaque paire d'équipes `(home_team,away_team)` de la division `Primera Division`, comptez le nombre de défaites de l'équipe locale. Transformez ce résultat sous forme d'un tableau contenant des nombres entiers : les `away_team` sont les colonnes et les valeurs nulles doivent être remplacées par des zéros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = df[(df['division'] == \"Primera Division\") & (df['home_score'] < df['away_score'])]\n",
    "tableau = selection.groupby(['home_team', 'away_team'])['date'].count().unstack()\n",
    "tableau.fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour `jobs.json`\n",
    "Faites afficher la liste des métiers qui sont de plus en plus populaires auprès des femmes de la dernière année de recensement. Le critère de popularité croissante est basé sur la médiane de `count` : on veut les métiers pour lesquels le `count` est entre la médiane et deux fois la médiane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = df[(df['sex'] == \"women\") & (df['year'] == df['year'].max())]\n",
    "mediane = selection['count'].median()\n",
    "selection[(mediane < selection['count']) & (selection['count'] < 2 * mediane)]['job']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour `movies.json`\n",
    "Pour chaque distributeur, obtenez le nombre de films ayant à la fois :\n",
    "* une note de 80 ou plus sur `Rotten Tomatoes Rating`,\n",
    "* une note de 8.0 ou plus sur `IMDB Rating` lorsque le nombre de votes est supérieur à 100000,\n",
    "* des revenus mondiaux excédant le budget de production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[(df['Rotten Tomatoes Rating'] >= 80) &\n",
    "   (df['IMDB Rating'] >= 8.0) & (df['IMDB Votes'] > 100000) &\n",
    "   (df['Worldwide Gross'] > df['Production Budget'])].groupby('Distributor')['Title'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour `penguins.json`\n",
    "Sélectionnez les pingouins dont la longueur du bec (`Beak`) est plus de trois fois la profondeur du bec. Ne gardez que les enregistrements pour lesquel le `Sex` est non-nul. Sauvegardez le tout dans le fichier `pointus.csv`, mais sans l'index par défaut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointus = df[(df['Beak Length (mm)'] > 3 * df['Beak Depth (mm)']) &\n",
    "             ~(pd.isnull(df['Sex']))]\n",
    "pointus.to_csv(\"pointus.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour `weather.csv`\n",
    "* Pendant tout l'hiver de l'année 2012 (jusqu'au 21 mars inclusivement), quelle est la quantité totale de neige qui est tombée dans chacune des villes concernées?\n",
    "* Pour chaque ville, à quelle date est tombée la dernière neige d'hiver ou de printemps en 2012?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['date'] <= \"2012-03-21\") &\n",
    "   (df['weather'] == \"snow\")].groupby('location')['precipitation'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['date'] <= \"2012-06-21\") &\n",
    "   (df['weather'] == \"snow\")].groupby('location')['date'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3 - Combiner des données\n",
    "Les clés de jonction compatibles étant rares dans les différents jeux de données Vega, il n'y a que deux paires de DataFrames à considérer (au choix). On va débuter par charger les trois fichiers concernés :\n",
    "\n",
    "* `airports.csv`\n",
    "* `flights-3m.csv`\n",
    "* `zipcodes.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeroports = pd.read_csv(os.path.join(dossier_data, \"airports.csv\"))\n",
    "vols =      pd.read_csv(os.path.join(dossier_data, \"flights-3m.csv\"))\n",
    "zipcodes =  pd.read_csv(os.path.join(dossier_data, \"zipcodes.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour `vols` et `aeroports`\n",
    "On veut calculer le délai moyen des vols pour toutes les paires d'aéroports `(origin,destination)` qui sont parmi les aéroports `ABQ`, `LAX`, `PHX` et `SAN`, sauf que le résultat final doit maintenant avoir le nom complet des villes concernées. Ces noms de ville sont disponibles dans le DataFrame `aeroports`. Indice : en joignant deux tables à répétition, les colonnes qui se répètent auront un suffixe unique.\n",
    "* Réduisez les informations dans `aeroports` pour ne garder que les rangées et les colonnes nécessaires.\n",
    "* Effectuez les jonctions en fonction des codes d'origine et de destination.\n",
    "* Calculez le délai moyen selon chaque paire de villes.\n",
    "* Transformez le résultat en tableau pour que chaque destination soit une colonne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes_iata = ['ABQ', 'LAX', 'PHX', 'SAN']\n",
    "aeroports_4x2 = aeroports[aeroports['iata'].isin(codes_iata)][['iata', 'city']]\n",
    "\n",
    "# Ajouter le nom des villes d'origine\n",
    "villes_o =  pd.merge(left=vols, left_on='origin', right=aeroports_4x2, right_on='iata')\n",
    "\n",
    "# Ajouter le nom des villes de destination\n",
    "villes_od = pd.merge(left=villes_o, left_on='destination', right=aeroports_4x2, right_on='iata')\n",
    "\n",
    "moyennes = villes_od.groupby(['city_x', 'city_y'])['delay'].mean()\n",
    "moyennes.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour `aeroports` et `zipcodes`\n",
    "Pour chaque aéroport, trouvez un code postal (`zip_code`) qui est le plus petit code associé à la combinaison `(city, state)` de l'aéroport. Le résultat final doit être un tableau ayant les colonnes `iata`, `name` et `zip_code`. Indice : l'index de rangées peut redevenir des colonnes à l'aide de la méthode `reset_index()`.\n",
    "* Effectuez la jonction entre les aéroports et les codes postaux selon la double clé de jonction `['city', 'state']`.\n",
    "* Calculez le code minimal pour chaque aéroport et remettre les colonnes `iata` et `name` à leur place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aero_zip = pd.merge(left=aeroports, right=zipcodes, on=['city', 'state'])\n",
    "aero_zip.groupby(['iata','name'])['zip_code'].min().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
